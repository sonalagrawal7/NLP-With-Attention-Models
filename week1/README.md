# Neural Machine Translation
Discover some of the shortcomings of a traditional seq2seq model and how to solve for them by adding an attention mechanism, then build a Neural Machine Translation model with Attention that translates English sentences into German.

# Learning Objectives
1. Explain how an Encoder/Decoder model works
2. Apply word alignment for machine translation
3. Train a Neural Machine Translation model with Attention
4. Develop intuition for how teacher forcing helps a translation model checks its predictions
5. Use BLEU score and ROUGE score to evaluate machine-generated text quality
6. Describe several decoding methods including MBR and Beam search


# Programming Assignment
NMT with Attention
